{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdwVJAa88Gfn",
        "outputId": "f55225ed-5e2b-4c6f-8d9c-77a33694757f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.3.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=f263643b27d896811fb10e29f967213ac8606c16ca0723736230ff556e57c3b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning -q\n",
        "!python -m spacy download en_core_web_md -q\n",
        "!pip install -U deep-translator -q\n",
        "!pip install -U youtube_transcript_api -q\n",
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa2TcrrY8MFj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pytorch_lightning as pl\n",
        "import datetime\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "from torchviz import make_dot\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import spacy\n",
        "\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "import json\n",
        "import math\n",
        "import plotly.express as px\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHlut0-x8WZy",
        "outputId": "1b68b1df-dcb7-43a5-b198-4cbc0935c194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/b5/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUxHoUva8a49"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFHLtOaT8iA1"
      },
      "outputs": [],
      "source": [
        "indices_to_labels = { 0:'e', 1:'n', 2:'a', 3:'c', 4:'o' }\n",
        "labels_to_indices = { 'e':0, 'n':1, 'a':2, 'c':3, 'o':4 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1CUZOS18l68"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ModelWithoutMRC(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "        self.padding = (3, 0)\n",
        "        self.stride = (6, 1)\n",
        "        self.kernel = (6, 1)\n",
        "        self.GRU = nn.GRU(300, 300, batch_first=True)\n",
        "        self.GRU1 = nn.GRU(300, 300, batch_first=True)\n",
        "        self.fc1 = nn.Linear(200 * 300, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, vectors, mrc):\n",
        "        x = vectors.unsqueeze(1)\n",
        "        x = self.GRU(x.squeeze(1))[0]\n",
        "        x = self.GRU1(x)[0]\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = F.sigmoid(self(inputs, mrc))\n",
        "\n",
        "        mse = torch.mean((outputs - labels)**2)\n",
        "        self.log('test_mse', mse, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-6)\n",
        "\n",
        "\n",
        "class ModelWithMRC(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "        self.padding = (3, 0)\n",
        "        self.stride = (6, 1)\n",
        "        self.kernel = (6, 1)\n",
        "        self.GRU = nn.GRU(300, 300, batch_first=True)\n",
        "        self.GRU1 = nn.GRU(300, 300, batch_first=True)\n",
        "        self.fc1 = nn.Linear(200 * 300, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128 + 27, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, vectors, mrc):\n",
        "        x = vectors.unsqueeze(1)\n",
        "        x = self.GRU(x.squeeze(1))[0]\n",
        "        x = self.GRU1(x)[0]\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(torch.cat([x, mrc], dim=1)))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = F.sigmoid(self(inputs, mrc))\n",
        "\n",
        "        mse = torch.mean((outputs - labels)**2)\n",
        "        self.log('test_mse', mse, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AX5pWhKc4J1k"
      },
      "outputs": [],
      "source": [
        "class NNModelWithoutMRC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "        self.padding = (3, 0)\n",
        "        self.stride = (6, 1)\n",
        "        self.kernel = (6, 1)\n",
        "        self.GRU = nn.GRU(300, 300, batch_first=True)\n",
        "        self.GRU1 = nn.GRU(300, 300, batch_first=True)\n",
        "        self.fc1 = nn.Linear(200 * 300, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, vectors, mrc):\n",
        "        x = vectors.unsqueeze(1)\n",
        "        x = self.GRU(x.squeeze(1))[0]\n",
        "        x = self.GRU1(x)[0]\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = F.sigmoid(self(inputs, mrc))\n",
        "\n",
        "        mse = torch.mean((outputs - labels)**2)\n",
        "        self.log('test_mse', mse, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-6)\n",
        "\n",
        "\n",
        "class NNModelWithMRC(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "        self.padding = (3, 0)\n",
        "        self.stride = (6, 1)\n",
        "        self.kernel = (6, 1)\n",
        "        self.GRU = nn.GRU(300, 300, batch_first=True)\n",
        "        self.GRU1 = nn.GRU(300, 300, batch_first=True)\n",
        "        self.fc1 = nn.Linear(200 * 300, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128 + 27, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "\n",
        "    def forward(self, vectors, mrc):\n",
        "        x = vectors.unsqueeze(1)\n",
        "        x = self.GRU(x.squeeze(1))[0]\n",
        "        x = self.GRU1(x)[0]\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(torch.cat([x, mrc], dim=1)))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = self(inputs, mrc)\n",
        "\n",
        "        loss = self.loss(outputs, labels.float())\n",
        "\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
        "\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        inputs, mrc, labels = batch\n",
        "        outputs = F.sigmoid(self(inputs, mrc))\n",
        "\n",
        "        mse = torch.mean((outputs - labels)**2)\n",
        "        self.log('test_mse', mse, on_step=False, on_epoch=True)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBKsqjWJ8x-c"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'e': ModelWithMRC.load_from_checkpoint(checkpoint_path=path+\"best-models/e-model.ckpt\"),\n",
        "    'n': ModelWithMRC.load_from_checkpoint(checkpoint_path=path+\"best-models/n-model.ckpt\"),\n",
        "    'a': ModelWithMRC.load_from_checkpoint(checkpoint_path=path+\"best-models/a-model.ckpt\"),\n",
        "    'c': ModelWithMRC.load_from_checkpoint(checkpoint_path=path+\"best-models/c-model.ckpt\"),\n",
        "    'o': ModelWithMRC.load_from_checkpoint(checkpoint_path=path+\"best-models/o-model.ckpt\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYXl9uoT-APB"
      },
      "outputs": [],
      "source": [
        "class FinalModel(nn.Module):\n",
        "    def __init__(self, models_info):\n",
        "        super().__init__()\n",
        "\n",
        "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
        "        for model_name in [\"e\", \"n\", \"a\", \"c\", \"o\"]:\n",
        "            model_info = models_info[model_name]\n",
        "            if model_info[\"with_mrc\"]:\n",
        "                model = NNModelWithMRC()\n",
        "            else:\n",
        "                model = NNModelWithoutMRC()\n",
        "            model.load_state_dict(model_info[\"state_dict\"])\n",
        "            setattr(self, model_name, model)\n",
        "\n",
        "    def forward(self, v, m):\n",
        "        return torch.cat([self.e(v, m), self.n(v, m), self.a(v, m), self.c(v, m), self.o(v, m)], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ6Vt3anAEd0"
      },
      "outputs": [],
      "source": [
        "all_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    all_models[name] = {'state_dict': model.state_dict(), 'with_mrc': isinstance(model, ModelWithMRC)}\n",
        "\n",
        "torch.save(all_models, path+\"best-models/models_info.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT-AHObW_Fd6"
      },
      "outputs": [],
      "source": [
        "models_info = torch.load(path+\"best-models/models_info.pth\")\n",
        "fModel = FinalModel(models_info)\n",
        "\n",
        "fModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uETu5N8g_tW0"
      },
      "outputs": [],
      "source": [
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMXZF87uJAUM"
      },
      "outputs": [],
      "source": [
        "with open(f'{path}mrc2_dict.json', 'r') as f:\n",
        "    word_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMNa3PvNLn8f"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv(f'{path}Big-Five_Backstage.csv')\n",
        "\n",
        "df2 = pd.read_csv(f'{path}essays/essays.csv', encoding='cp1252', delimiter=',', quotechar='\"')\n",
        "df2 = df2.rename(columns={'TEXT': 'text',\n",
        "                        'cEXT': 'Extraversion',\n",
        "                        'cNEU': 'Neuroticism',\n",
        "                        'cAGR': 'Agreeableness',\n",
        "                        'cCON': 'Conscientiousness',\n",
        "                        'cOPN': 'Openness'})\n",
        "keys =  ['Extraversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']\n",
        "df2[keys] = df2[keys].replace({'y': 1.0, 'n': 0.0})\n",
        "texts = pd.concat([df1['text'], df2['text']], ignore_index=True)\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz7XaRgVMno4"
      },
      "outputs": [],
      "source": [
        "def evalText(text):\n",
        "  fModel.eval()\n",
        "  fModel.to(device)\n",
        "  # with torch.no_grad():\n",
        "  input = torch.zeros((200, 300), device=device, dtype=torch.float32)\n",
        "  mrc = np.zeros(27)\n",
        "  words = []\n",
        "  for word in nlp(text)[:200]:\n",
        "    if word.lemma_ in word_data:\n",
        "      mrc += np.array(word_data[word.lemma_])\n",
        "    if word.has_vector and word.is_alpha:\n",
        "      words.append(word.vector)\n",
        "\n",
        "  mrc = torch.tensor(np.array(mrc), device=device, dtype=torch.float32).unsqueeze(0)\n",
        "  mrc = mrc / torch.norm(mrc, p=2, dim=1, keepdim=True)\n",
        "  mrc = torch.nan_to_num(mrc, nan=0)\n",
        "\n",
        "  words = torch.tensor(np.array(words), device=device, dtype=torch.float32)\n",
        "  input[:words.shape[0]] = words\n",
        "  input = input.unsqueeze(0)\n",
        "  input = torch.tensor(input, device=device, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "  writer = SummaryWriter(log_dir='logs')\n",
        "  writer.add_graph(fModel, (input, mrc))\n",
        "  writer.close()\n",
        "\n",
        "  raw_outputs = fModel(input, mrc)\n",
        "  outputs = F.sigmoid(raw_outputs).squeeze()\n",
        "  return (outputs, raw_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NT6D6pAXBiV"
      },
      "outputs": [],
      "source": [
        "def drawplt1(data):\n",
        "  sns.set_style(\"whitegrid\")\n",
        "\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  plt.xlim(0, 100)\n",
        "  sns.barplot(x=data, y=label_names, hue=label_names, legend=False)\n",
        "\n",
        "  for i, v in enumerate(data):\n",
        "      vv = round(v, 2)\n",
        "      plt.text(vv + 1, i, str(vv)+'%', color='black', va='center', fontsize=12)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k17k2O9_hm3"
      },
      "outputs": [],
      "source": [
        "def drawplt2(data):\n",
        "  ln = label_names.copy()\n",
        "  ln.append(ln[0])\n",
        "  lab = (np.array(raw_predicted_labels) * 100).tolist()\n",
        "  lab.append(lab[0])\n",
        "\n",
        "  df = pd.DataFrame(dict(r=lab, theta=ln))\n",
        "  fig = px.line_polar(df, r='r', theta='theta', line_close=True)\n",
        "  fig.update_traces(fill='toself')\n",
        "  fig.update_layout(\n",
        "      polar=dict(\n",
        "          radialaxis=dict(\n",
        "              tickvals=[0, 20, 40, 60, 80, 100],\n",
        "              ticktext=['0%', '20%', '40%', '60%', '80%', '100%'],\n",
        "              range=[0, 100]\n",
        "          )\n",
        "      )\n",
        "  )\n",
        "  fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q1Ed5V3jVBB"
      },
      "outputs": [],
      "source": [
        "def big5_to_mbti(big5):\n",
        "    res = \"\"\n",
        "    res += \"e\" if big5[0] >= 0.5 else \"i\"\n",
        "    res += \"n\" if big5[4] >= 0.5 else \"s\"\n",
        "    res += \"f\" if big5[2] >= 0.5 else \"t\"\n",
        "    res += \"j\" if big5[3] >= 0.5 else \"p\"\n",
        "    return res.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdFcpRV4PrMw"
      },
      "outputs": [],
      "source": [
        "label_names = ['Extroversion', 'Neuroticism', 'Agreeableness', 'Conscientiousness', 'Openness']\n",
        "text = \"Hi. What is your name? How old are you? Where are u from Hello fella brother\"\n",
        "text = GoogleTranslator(source='auto', target='en').translate(text)\n",
        "\n",
        "k = 1\n",
        "for text in texts[k:k+1]:\n",
        "  text = GoogleTranslator(source='auto', target='en').translate(text)\n",
        "  outputs, raw_outputs = evalText(text)\n",
        "  raw_predicted_labels = outputs.float().tolist()\n",
        "  predicted_labels = (outputs > 0.5).float().tolist()\n",
        "  result1 = {label_names[i]: predicted_labels[i] for i in range(len(label_names))}\n",
        "  result2 = {label_names[i]: raw_predicted_labels[i] for i in range(len(label_names))}\n",
        "  print(big5_to_mbti(raw_predicted_labels))\n",
        "  drawplt1((outputs.float() * 100).tolist())\n",
        "  drawplt2((outputs.float() * 100).tolist())\n",
        "  print(result1)\n",
        "  print(result2)\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
